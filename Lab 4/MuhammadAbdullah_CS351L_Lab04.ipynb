{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CS 351 Lab 3**\n",
        "## Introduction to Constraint Satisfaction Problems (CSP)\n"
      ],
      "metadata": {
        "id": "XIakfXGUmZlW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Student Details**\n",
        "\n",
        "### **Name:** Muhammad Abdullah\n",
        "### **Reg:** 2022323\n"
      ],
      "metadata": {
        "id": "ZSq4JJ9xmmJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lab Task**\n",
        "\n",
        "Scenario:\n",
        "You are hired as a data scientist for a university. The university wants to predict whether\n",
        "passengers survived the Titanic disaster based on various factors such as their age, gender,\n",
        "ticket class, and fare paid. You will use the k-NN and Decision Tree algorithms to build\n",
        "models that predict whether a passenger survived.\n",
        "Part 1: Data Exploration and Preprocessing\n",
        "1. Explore the Dataset:\n",
        "- Load the dataset and display the first few rows.\n",
        "- Visualize the distribution of key features (like `Pclass`, `Age`, `Sex`, etc.).\n",
        "- Check for any missing values or outliers.\n",
        "2. Data Preprocessing:\n",
        "- Handle missing values by either filling them (e.g., with median) or removing records\n",
        "with missing data.\n",
        "- Encode categorical variables like `Sex` and `Embarked` into numerical values.\n",
        "- Standardize or normalize the numerical features like `Age` and `Fare`.\n",
        "Part 2: Implementing k-NN and Decision Trees\n",
        "1. Model Training:\n",
        "- Split the dataset into training and testing sets (70% training, 30% testing).\n",
        "- Implement the k-Nearest Neighbors (k-NN) algorithm and train the model using the\n",
        "training set.\n",
        "- Implement a Decision Tree algorithm and train it using the same training set.\n",
        "2. Model Evaluation:\n",
        "- Use the test set to make predictions for both models.\n",
        "- Evaluate the performance of each model using accuracy, precision, recall, and F1-score.\n",
        "- Compare the results and discuss which model performed better.\n",
        "Part 3: Visualization\n",
        "1. Decision Boundaries:\n",
        "- Create visualizations to display the decision boundaries of both models (k-NN and\n",
        "Decision Tree) using two features from the dataset.\n",
        "- Plot the data points along with the decision boundaries to show how each model\n",
        "classifies the data.\n",
        "2. Performance Visualization:\n",
        "- Plot a bar chart showing the performance metrics (accuracy, precision, recall, F1-score)\n",
        "of both models for easy comparison.\n",
        "Dataset Source:\n",
        "For this lab, you will use the publicly available Titanic dataset from Kaggle.\n",
        "Download it from the following link:\n",
        "https://www.kaggle.com/c/titanic/data\n",
        "How to Load the Dataset in Python:\n",
        "Use the following code to load the dataset:\n",
        "```python\n",
        "import pandas as pd\n",
        "# Load the dataset\n",
        "url = 'https://www.kaggle.com/c/titanic/data'\n",
        "titanic_data = pd.read_csv('train.csv')\n",
        "print(titanic_data.head())\n"
      ],
      "metadata": {
        "id": "eP-O5trn0jWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Solution**\n",
        "\n",
        "**Part 1:**\n",
        "\n",
        "Data Exploration and Preprocessing\n",
        "Loading and Exploring the Dataset:\n"
      ],
      "metadata": {
        "id": "Hi8KoOBz0sgq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "# Load the dataset\n",
        "titanic_data = pd.read_csv('train.csv')\n",
        "print(titanic_data.head())\n",
        "# Check for missing values and data types\n",
        "print(titanic_data.info())"
      ],
      "metadata": {
        "id": "hWL5TUOY09Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Key Features: You can plot distributions for features like Pclass, Age, Sex, etc.\n"
      ],
      "metadata": {
        "id": "4o4x0Jsq0_lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(x='Pclass', data=titanic_data)\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(titanic_data['Age'].dropna(), bins=30)\n",
        "plt.show()\n",
        "\n",
        "sns.countplot(x='Sex', data=titanic_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FJ2aP0WN1Gyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling Missing Values: You can fill missing values in the Age column with the median and drop rows with missing values in the Embarked column.\n"
      ],
      "metadata": {
        "id": "cJq1nX_D1LPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_data['Age'].fillna(titanic_data['Age'].median(), inplace=True)\n",
        "titanic_data.dropna(subset=['Embarked'], inplace=True)"
      ],
      "metadata": {
        "id": "6JnPMhnf1T1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Categorical Variables: Encode Sex and Embarked columns."
      ],
      "metadata": {
        "id": "Ax3Gnyil1VCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_data['Sex'] = titanic_data['Sex'].map({'male': 0, 'female': 1})\n",
        "titanic_data = pd.get_dummies(titanic_data, columns=['Embarked'], drop_first=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nDSa9tE11aeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling (optional): You can standardize numerical features like Age and Fare:\n"
      ],
      "metadata": {
        "id": "3JbTveBq10v9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "titanic_data[['Age', 'Fare']] = scaler.fit_transform(titanic_data[['Age', 'Fare']])"
      ],
      "metadata": {
        "id": "wLUXjA0O18hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2:**\n",
        "\n",
        "Implementing k-NN and Decision Trees"
      ],
      "metadata": {
        "id": "s_NZZ2ef2aJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the Data: Prepare the data for training."
      ],
      "metadata": {
        "id": "97AqGn612erj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = titanic_data[['Pclass', 'Sex', 'Age', 'Fare']]\n",
        "y = titanic_data['Survived']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "zWuI-S2x2iVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement k-NN: Train the k-NN model and make predictions."
      ],
      "metadata": {
        "id": "juJ24Vlo2kaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n"
      ],
      "metadata": {
        "id": "L8Tj_Hgg2nB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement Decision Tree: Train a Decision Tree classifier."
      ],
      "metadata": {
        "id": "Xz5Luhee2pJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X_train, y_train)\n",
        "y_pred_dtree = dtree.predict(X_test)\n"
      ],
      "metadata": {
        "id": "j2TOaaHS2sgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate Models: Evaluate both models using accuracy, precision, recall, and F1-score."
      ],
      "metadata": {
        "id": "Ewzri5qT2vVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"k-NN Classification Report:\\n\", classification_report(y_test, y_pred_knn))\n",
        "print(\"Decision Tree Classification Report:\\n\", classification_report(y_test, y_pred_dtree))\n"
      ],
      "metadata": {
        "id": "5crQn5G52wCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3:**\n",
        "\n",
        "Visualization"
      ],
      "metadata": {
        "id": "pgKpG3Y22zb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Boundaries: You can visualize the decision boundaries using two features (e.g., Pclass and Fare)."
      ],
      "metadata": {
        "id": "Q0fdSqIj23rv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_boundary(X, y, model):\n",
        "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
        "    cmap_bold = ListedColormap(['#FF0000', '#00FF00'])\n",
        "\n",
        "    h = .02  # step size in the mesh\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    plt.contourf(xx, yy, Z, cmap=cmap_light)\n",
        "\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IJMEDNaS26HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Metrics Visualization: Plot a bar chart comparing accuracy, precision, recall, and F1-score for both models."
      ],
      "metadata": {
        "id": "ocK35pyr28f2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n",
        "knn_scores = [0.8, 0.75, 0.78, 0.76]  # Example scores for k-NN\n",
        "dtree_scores = [0.85, 0.80, 0.83, 0.82]  # Example scores for Decision Tree\n",
        "\n",
        "X_axis = np.arange(len(metrics))\n",
        "plt.bar(X_axis - 0.2, knn_scores, 0.4, label='k-NN')\n",
        "plt.bar(X_axis + 0.2, dtree_scores, 0.4, label='Decision Tree')\n",
        "plt.xticks(X_axis, metrics)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Jgjcw-_I29bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By following these steps, you can predict the survival of Titanic passengers and compare the performance of k-NN and Decision Tree classifiers."
      ],
      "metadata": {
        "id": "OKf6ETA33Ah8"
      }
    }
  ]
}